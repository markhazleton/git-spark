import { AnalysisReport } from '../types';
import { writeFileSync, mkdirSync } from 'fs';
import { resolve, dirname } from 'path';
import { createLogger } from '../utils/logger';

const logger = createLogger('markdown-exporter');

export class MarkdownExporter {
  async export(report: AnalysisReport, outputPath: string): Promise<void> {
    try {
      const fullPath = resolve(outputPath, 'git-spark-report.md');

      // Ensure directory exists
      mkdirSync(dirname(fullPath), { recursive: true });

      // Generate Markdown content
      const markdownContent = this.generateMarkdown(report);

      // Write to file
      writeFileSync(fullPath, markdownContent, 'utf-8');

      logger.info('Markdown report exported successfully', { path: fullPath });
    } catch (error) {
      logger.error('Failed to export Markdown report', { error, outputPath });
      throw error;
    }
  }

  private generateMarkdown(report: AnalysisReport): string {
    const { repository, summary, authors, files, risks, governance } = report;

    return `# ðŸ”¥ Git Spark Report

Generated on ${report.metadata.generatedAt.toLocaleDateString()}

## ðŸ“Š Executive Summary

**Repository Health: ${summary.healthRating.toUpperCase()}**

| Metric | Value |
|--------|-------|
| Total Commits | ${repository.totalCommits} |
| Contributors | ${repository.totalAuthors} |
| Files Changed | ${repository.totalFiles} |
| Health Score | ${Math.round(repository.healthScore * 100)}% |
| Bus Factor | ${repository.busFactor} |

${
  summary.insights.length > 0
    ? `
### ðŸ’¡ Key Insights

${summary.insights.map(insight => `- ${insight}`).join('\n')}
`
    : ''
}

${
  summary.actionItems.length > 0
    ? `
### ðŸš¨ Action Items

${summary.actionItems.map(item => `- ${item}`).join('\n')}
`
    : ''
}

## ðŸ“ Repository Overview

- **Active Period:** ${repository.activeDays} days
- **Average Commits/Day:** ${repository.avgCommitsPerDay.toFixed(2)}
- **Total Code Churn:** ${repository.totalChurn.toLocaleString()} lines
- **Governance Score:** ${Math.round(governance.score * 100)}%

### ðŸ’» Languages

${Object.entries(repository.languages)
  .map(([lang, count]) => `- ${lang}: ${count}`)
  .join('\n')}

## ðŸ‘¥ Top Contributors

| Author | Commits | Churn | Files | Avg Commit Size |
|--------|---------|-------|-------|-----------------|
${authors
  .slice(0, 10)
  .map(
    author =>
      `| ${author.name} | ${author.commits} | ${author.churn.toLocaleString()} | ${author.filesChanged} | ${Math.round(author.avgCommitSize)} |`
  )
  .join('\n')}

## ðŸ”¥ File Hotspots

| File | Commits | Authors | Churn | Risk Score |
|------|---------|---------|-------|------------|
${files
  .slice(0, 15)
  .map(
    file =>
      `| \`${file.path}\` | ${file.commits} | ${file.authors.length} | ${file.churn.toLocaleString()} | ${Math.round(file.riskScore * 100)}% |`
  )
  .join('\n')}

## âš ï¸ Risk Analysis

**Overall Risk Level: ${risks.overallRisk.toUpperCase()}**

### Risk Factors
- High churn files: ${risks.riskFactors.highChurnFiles}
- Files with many authors: ${risks.riskFactors.manyAuthorFiles}
- Large commits: ${risks.riskFactors.largeCommits}
- Recently changed files: ${risks.riskFactors.recentChanges}

${
  risks.recommendations.length > 0
    ? `
### Recommendations
${risks.recommendations.map(rec => `- ${rec}`).join('\n')}
`
    : ''
}

## ðŸ“‹ Governance Analysis

**Governance Score: ${Math.round(governance.score * 100)}%**

- **Conventional Commits:** ${governance.conventionalCommits}
- **Traceability Score:** ${Math.round(governance.traceabilityScore * 100)}%
- **Average Message Length:** ${Math.round(governance.avgMessageLength)} characters
- **WIP Commits:** ${governance.wipCommits}
- **Revert Commits:** ${governance.revertCommits}
- **Short Messages:** ${governance.shortMessages}

${
  governance.recommendations.length > 0
    ? `
### Recommendations
${governance.recommendations.map(rec => `- ${rec}`).join('\n')}
`
    : ''
}

---

*Generated by git-spark v${report.metadata.version} in ${report.metadata.processingTime}ms*
`;
  }
}
